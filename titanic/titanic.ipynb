{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(axis = 0, subset = ['Age'] )\n",
    "#train_data = train_data.fillna(value={'Age': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Survived       False\n",
       "Pclass         False\n",
       "Sex            False\n",
       "Age            False\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Fare           False\n",
       "Embarked        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data.Sex == 'male', 'Sex'] = 1\n",
    "train_data.loc[train_data.Sex == 'female', 'Sex'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data.Embarked == 'S', 'Embarked'] = 1\n",
    "train_data.loc[train_data.Embarked == 'C', 'Embarked'] = 2\n",
    "train_data.loc[train_data.Embarked == 'Q', 'Embarked'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(value={'Embarked': 0})\n",
    "#train_data = train_data.dropna(axis = 0, subset = ['Embarked'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0            1         0       3    1  22.0      1      0   7.2500         1\n",
       "1            2         1       1    0  38.0      1      0  71.2833         2\n",
       "2            3         1       3    0  26.0      0      0   7.9250         1\n",
       "3            4         1       1    0  35.0      1      0  53.1000         1\n",
       "4            5         0       3    1  35.0      0      0   8.0500         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Survived       False\n",
       "Pclass         False\n",
       "Sex            False\n",
       "Age            False\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Fare           False\n",
       "Embarked       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_set = train_data['PassengerId']\n",
    "label_set = train_data['Survived']\n",
    "data_set = train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      False\n",
       "Sex         False\n",
       "Age         False\n",
       "SibSp       False\n",
       "Parch       False\n",
       "Fare        False\n",
       "Embarked    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = data_set\n",
    "y = label_set\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 7)\n",
      "<class 'pandas.core.series.Series'>\n",
      "(215, 7)\n",
      "(215,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(type(y_train))\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\program\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\program\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.as_matrix().reshape((499, 1))\n",
    "y_test = y_test.as_matrix().reshape((215, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data_x,data_y,batch_size=32):\n",
    "    batch_n=len(data_x)//batch_size\n",
    "    for i in range(batch_n):\n",
    "        batch_x=data_x[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y=data_y[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        yield batch_x,batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\program\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_steps = 500\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "\n",
    "n_hidden_1 = 10\n",
    "num_input = 7\n",
    "num_classes = 1\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, num_input])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "def neural_network(x):\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    out_layer = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "logits = neural_network(x)\n",
    "\n",
    "# loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "# loss_op = tf.reduce_mean((logits - y) ** 2)\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "predicted = tf.nn.sigmoid(logits)\n",
    "correct_pred = tf.equal(tf.round(predicted), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/200 Train Loss: 0.5738 Train Acc: 0.7796\n",
      "Epoch: 4/200 Validation Loss: 0.5278 Validation Acc: 0.7953\n",
      "Epoch: 7/200 Train Loss: 0.6198 Train Acc: 0.7756\n",
      "Epoch: 7/200 Validation Loss: 0.5492 Validation Acc: 0.8000\n",
      "Epoch: 10/200 Train Loss: 0.5251 Train Acc: 0.7896\n",
      "Epoch: 10/200 Validation Loss: 0.4841 Validation Acc: 0.7860\n",
      "Epoch: 13/200 Train Loss: 0.5031 Train Acc: 0.7856\n",
      "Epoch: 13/200 Validation Loss: 0.5028 Validation Acc: 0.8000\n",
      "Epoch: 17/200 Train Loss: 0.4139 Train Acc: 0.8196\n",
      "Epoch: 17/200 Validation Loss: 0.4877 Validation Acc: 0.8093\n",
      "Epoch: 20/200 Train Loss: 0.3975 Train Acc: 0.8297\n",
      "Epoch: 20/200 Validation Loss: 0.4661 Validation Acc: 0.8000\n",
      "Epoch: 23/200 Train Loss: 0.3966 Train Acc: 0.8236\n",
      "Epoch: 23/200 Validation Loss: 0.4672 Validation Acc: 0.8047\n",
      "Epoch: 26/200 Train Loss: 0.4134 Train Acc: 0.8156\n",
      "Epoch: 26/200 Validation Loss: 0.5285 Validation Acc: 0.7953\n",
      "Epoch: 30/200 Train Loss: 0.3865 Train Acc: 0.8277\n",
      "Epoch: 30/200 Validation Loss: 0.4797 Validation Acc: 0.7907\n",
      "Epoch: 33/200 Train Loss: 0.3827 Train Acc: 0.8317\n",
      "Epoch: 33/200 Validation Loss: 0.4805 Validation Acc: 0.7907\n",
      "Epoch: 36/200 Train Loss: 0.3807 Train Acc: 0.8297\n",
      "Epoch: 36/200 Validation Loss: 0.4826 Validation Acc: 0.7907\n",
      "Epoch: 39/200 Train Loss: 0.3812 Train Acc: 0.8337\n",
      "Epoch: 39/200 Validation Loss: 0.4898 Validation Acc: 0.7953\n",
      "Epoch: 42/200 Train Loss: 0.3787 Train Acc: 0.8297\n",
      "Epoch: 42/200 Validation Loss: 0.4852 Validation Acc: 0.7953\n",
      "Epoch: 46/200 Train Loss: 0.3797 Train Acc: 0.8377\n",
      "Epoch: 46/200 Validation Loss: 0.4896 Validation Acc: 0.7907\n",
      "Epoch: 49/200 Train Loss: 0.3851 Train Acc: 0.8517\n",
      "Epoch: 49/200 Validation Loss: 0.4932 Validation Acc: 0.8000\n",
      "Epoch: 52/200 Train Loss: 0.3838 Train Acc: 0.8397\n",
      "Epoch: 52/200 Validation Loss: 0.4571 Validation Acc: 0.7860\n",
      "Epoch: 55/200 Train Loss: 0.3816 Train Acc: 0.8277\n",
      "Epoch: 55/200 Validation Loss: 0.4574 Validation Acc: 0.8140\n",
      "Epoch: 59/200 Train Loss: 0.3885 Train Acc: 0.8257\n",
      "Epoch: 59/200 Validation Loss: 0.4787 Validation Acc: 0.8140\n",
      "Epoch: 62/200 Train Loss: 0.3879 Train Acc: 0.8277\n",
      "Epoch: 62/200 Validation Loss: 0.4597 Validation Acc: 0.8279\n",
      "Epoch: 65/200 Train Loss: 0.3798 Train Acc: 0.8357\n",
      "Epoch: 65/200 Validation Loss: 0.4854 Validation Acc: 0.8279\n",
      "Epoch: 68/200 Train Loss: 0.3844 Train Acc: 0.8216\n",
      "Epoch: 68/200 Validation Loss: 0.4633 Validation Acc: 0.8093\n",
      "Epoch: 71/200 Train Loss: 0.3715 Train Acc: 0.8437\n",
      "Epoch: 71/200 Validation Loss: 0.4879 Validation Acc: 0.8140\n",
      "Epoch: 75/200 Train Loss: 0.3720 Train Acc: 0.8397\n",
      "Epoch: 75/200 Validation Loss: 0.4761 Validation Acc: 0.8047\n",
      "Epoch: 78/200 Train Loss: 0.3711 Train Acc: 0.8497\n",
      "Epoch: 78/200 Validation Loss: 0.4754 Validation Acc: 0.7814\n",
      "Epoch: 81/200 Train Loss: 0.3763 Train Acc: 0.8457\n",
      "Epoch: 81/200 Validation Loss: 0.4710 Validation Acc: 0.8140\n",
      "Epoch: 84/200 Train Loss: 0.4467 Train Acc: 0.8116\n",
      "Epoch: 84/200 Validation Loss: 0.5980 Validation Acc: 0.7860\n",
      "Epoch: 88/200 Train Loss: 0.3718 Train Acc: 0.8437\n",
      "Epoch: 88/200 Validation Loss: 0.5061 Validation Acc: 0.8233\n",
      "Epoch: 91/200 Train Loss: 0.3735 Train Acc: 0.8437\n",
      "Epoch: 91/200 Validation Loss: 0.4853 Validation Acc: 0.8186\n",
      "Epoch: 94/200 Train Loss: 0.3742 Train Acc: 0.8397\n",
      "Epoch: 94/200 Validation Loss: 0.4745 Validation Acc: 0.8186\n",
      "Epoch: 97/200 Train Loss: 0.3768 Train Acc: 0.8457\n",
      "Epoch: 97/200 Validation Loss: 0.4961 Validation Acc: 0.7953\n",
      "Epoch: 100/200 Train Loss: 0.3752 Train Acc: 0.8417\n",
      "Epoch: 100/200 Validation Loss: 0.4835 Validation Acc: 0.8093\n",
      "Epoch: 104/200 Train Loss: 0.3779 Train Acc: 0.8357\n",
      "Epoch: 104/200 Validation Loss: 0.4859 Validation Acc: 0.8093\n",
      "Epoch: 107/200 Train Loss: 0.4807 Train Acc: 0.8096\n",
      "Epoch: 107/200 Validation Loss: 0.7487 Validation Acc: 0.7767\n",
      "Epoch: 110/200 Train Loss: 0.3787 Train Acc: 0.8377\n",
      "Epoch: 110/200 Validation Loss: 0.4930 Validation Acc: 0.8000\n",
      "Epoch: 113/200 Train Loss: 0.3761 Train Acc: 0.8377\n",
      "Epoch: 113/200 Validation Loss: 0.4957 Validation Acc: 0.7907\n",
      "Epoch: 117/200 Train Loss: 0.3744 Train Acc: 0.8377\n",
      "Epoch: 117/200 Validation Loss: 0.4857 Validation Acc: 0.7860\n",
      "Epoch: 120/200 Train Loss: 0.3743 Train Acc: 0.8397\n",
      "Epoch: 120/200 Validation Loss: 0.4979 Validation Acc: 0.7814\n",
      "Epoch: 123/200 Train Loss: 0.3804 Train Acc: 0.8236\n",
      "Epoch: 123/200 Validation Loss: 0.4929 Validation Acc: 0.8093\n",
      "Epoch: 126/200 Train Loss: 0.3751 Train Acc: 0.8437\n",
      "Epoch: 126/200 Validation Loss: 0.5119 Validation Acc: 0.7814\n",
      "Epoch: 130/200 Train Loss: 0.3752 Train Acc: 0.8437\n",
      "Epoch: 130/200 Validation Loss: 0.5270 Validation Acc: 0.7814\n",
      "Epoch: 133/200 Train Loss: 0.3785 Train Acc: 0.8337\n",
      "Epoch: 133/200 Validation Loss: 0.4864 Validation Acc: 0.8140\n",
      "Epoch: 136/200 Train Loss: 0.3712 Train Acc: 0.8297\n",
      "Epoch: 136/200 Validation Loss: 0.4874 Validation Acc: 0.8186\n",
      "Epoch: 139/200 Train Loss: 0.3684 Train Acc: 0.8297\n",
      "Epoch: 139/200 Validation Loss: 0.4888 Validation Acc: 0.8093\n",
      "Epoch: 142/200 Train Loss: 0.3665 Train Acc: 0.8277\n",
      "Epoch: 142/200 Validation Loss: 0.4841 Validation Acc: 0.8233\n",
      "Epoch: 146/200 Train Loss: 0.3635 Train Acc: 0.8317\n",
      "Epoch: 146/200 Validation Loss: 0.4933 Validation Acc: 0.8233\n",
      "Epoch: 149/200 Train Loss: 0.5377 Train Acc: 0.7876\n",
      "Epoch: 149/200 Validation Loss: 0.5177 Validation Acc: 0.7674\n",
      "Epoch: 152/200 Train Loss: 0.3755 Train Acc: 0.8257\n",
      "Epoch: 152/200 Validation Loss: 0.4963 Validation Acc: 0.8000\n",
      "Epoch: 155/200 Train Loss: 0.3723 Train Acc: 0.8216\n",
      "Epoch: 155/200 Validation Loss: 0.4929 Validation Acc: 0.8140\n",
      "Epoch: 159/200 Train Loss: 0.3717 Train Acc: 0.8176\n",
      "Epoch: 159/200 Validation Loss: 0.5007 Validation Acc: 0.8000\n",
      "Epoch: 162/200 Train Loss: 0.4307 Train Acc: 0.8277\n",
      "Epoch: 162/200 Validation Loss: 0.5193 Validation Acc: 0.8000\n",
      "Epoch: 165/200 Train Loss: 0.3749 Train Acc: 0.8216\n",
      "Epoch: 165/200 Validation Loss: 0.4946 Validation Acc: 0.7953\n",
      "Epoch: 168/200 Train Loss: 0.3723 Train Acc: 0.8216\n",
      "Epoch: 168/200 Validation Loss: 0.4943 Validation Acc: 0.8047\n",
      "Epoch: 171/200 Train Loss: 0.3719 Train Acc: 0.8196\n",
      "Epoch: 171/200 Validation Loss: 0.4950 Validation Acc: 0.8047\n",
      "Epoch: 175/200 Train Loss: 0.3857 Train Acc: 0.8116\n",
      "Epoch: 175/200 Validation Loss: 0.5143 Validation Acc: 0.7674\n",
      "Epoch: 178/200 Train Loss: 0.3739 Train Acc: 0.8176\n",
      "Epoch: 178/200 Validation Loss: 0.5010 Validation Acc: 0.7953\n",
      "Epoch: 181/200 Train Loss: 0.3713 Train Acc: 0.8236\n",
      "Epoch: 181/200 Validation Loss: 0.4963 Validation Acc: 0.7907\n",
      "Epoch: 184/200 Train Loss: 0.3756 Train Acc: 0.8317\n",
      "Epoch: 184/200 Validation Loss: 0.5183 Validation Acc: 0.7953\n",
      "Epoch: 188/200 Train Loss: 0.3770 Train Acc: 0.8216\n",
      "Epoch: 188/200 Validation Loss: 0.5001 Validation Acc: 0.8000\n",
      "Epoch: 191/200 Train Loss: 0.3724 Train Acc: 0.8196\n",
      "Epoch: 191/200 Validation Loss: 0.4988 Validation Acc: 0.7907\n",
      "Epoch: 194/200 Train Loss: 0.3706 Train Acc: 0.8196\n",
      "Epoch: 194/200 Validation Loss: 0.5021 Validation Acc: 0.7814\n",
      "Epoch: 197/200 Train Loss: 0.4021 Train Acc: 0.8297\n",
      "Epoch: 197/200 Validation Loss: 0.5250 Validation Acc: 0.8140\n",
      "Epoch: 200/200 Train Loss: 0.3737 Train Acc: 0.8196\n",
      "Epoch: 200/200 Validation Loss: 0.5031 Validation Acc: 0.7953\n",
      "Accuracy:  0.7953488\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "train_collect = 50\n",
    "train_print=train_collect*2\n",
    "\n",
    "learning_rate_value = 0.001\n",
    "batch_size=16\n",
    "\n",
    "x_collect = []\n",
    "train_loss_collect = []\n",
    "train_acc_collect = []\n",
    "valid_loss_collect = []\n",
    "valid_acc_collect = []\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    iteration=0\n",
    "    for e in range(epochs):\n",
    "        for batch_x,batch_y in get_batch(x_train,y_train,batch_size):\n",
    "            iteration+=1\n",
    "            _, train_loss, train_acc = sess.run([train_op, loss_op, accuracy], feed_dict={x: x_train, y: y_train})\n",
    "            if iteration % train_collect == 0:\n",
    "                x_collect.append(e)\n",
    "                train_loss_collect.append(train_loss)\n",
    "                train_acc_collect.append(train_acc)\n",
    "\n",
    "                if iteration % train_print==0:\n",
    "                     print(\"Epoch: {}/{}\".format(e + 1, epochs),\n",
    "                      \"Train Loss: {:.4f}\".format(train_loss),\n",
    "                      \"Train Acc: {:.4f}\".format(train_acc))\n",
    "                \n",
    "                val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={x: x_test, y: y_test})\n",
    "                valid_loss_collect.append(val_loss)\n",
    "                valid_acc_collect.append(val_acc)\n",
    "                \n",
    "                if iteration % train_print==0:\n",
    "                    print(\"Epoch: {}/{}\".format(e + 1, epochs),\n",
    "                      \"Validation Loss: {:.4f}\".format(val_loss),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={x: x_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors  ===>  0.641860465116279\n",
      "Linear SVM  ===>  0.8046511627906977\n",
      "RBF SVM  ===>  0.5720930232558139\n",
      "Gaussian Process  ===>  0.8046511627906977\n",
      "Decision Tree  ===>  0.7906976744186046\n",
      "Random Forest  ===>  0.7534883720930232\n",
      "Neural Net  ===>  0.7674418604651163\n",
      "AdaBoost  ===>  0.8186046511627907\n",
      "Naive Bayes  ===>  0.7813953488372093\n",
      "QDA  ===>  0.786046511627907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(8),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(x_train, y_train)\n",
    "    score = clf.score(x_test, y_test)\n",
    "    print(name,\" ===> \",  score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
